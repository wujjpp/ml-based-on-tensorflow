{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归问题\n",
    "\n",
    "根据汽车属性参数预测油耗，可应用场景：预测气温、机器翻译、智能问答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入包，并打印版本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "boston_housing = tf.keras.datasets.boston_housing\n",
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "activations = tf.keras.activations\n",
    "optimizers = tf.keras.optimizers\n",
    "losses = tf.keras.losses\n",
    "\n",
    "print('tensorflow: ' + tf.__version__)\n",
    "print('pandas: ' + pd.__version__)\n",
    "print('numpy: ' + np.__version__)\n",
    "print('matplotlib: ' + matplotlib.__version__)\n",
    "print('seaborn: ' + sns.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备样本数据\n",
    "汽车数据\n",
    "\n",
    "| 栏位           | 说明                    |\n",
    "| :-------------------| :--------------------------------|\n",
    "| MPG            | 油耗， 需要预测的数据        |\n",
    "| Cylinders        | 汽缸数                  |\n",
    "| Displacement      | 排量                    |\n",
    "| Horsepower       | 马力                    |\n",
    "| Weight          | 总量                    |\n",
    "| Acceleration      | 加速度                  |\n",
    "| Model Year       | 生产年份                 |\n",
    "| Origin          | 产地， 1: 美国，2: 欧洲，3: 日本 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_path = tf.keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names, na_values = \"?\", comment='\\t',sep=\" \", skipinitialspace=True)\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 预处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 清理无效数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 查看无效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 清理无效数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 再来看一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 处理类别栏位\n",
    "`Origin`栏位通过值1，2，3来标识产地，这里把它转换成One-Hot模式，注意下面的输出，`Origin`栏位被移除，增加 `USA`、`Europe`、`Japan` 3个栏位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = dataset.pop('Origin')\n",
    "dataset['USA'] = (origin == 1)*1.0\n",
    "dataset['Europe'] = (origin == 2)*1.0\n",
    "dataset['Japan'] = (origin == 3)*1.0\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 将数据分离成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "print('dataset.shape: ' + str(dataset.shape))\n",
    "print('train_dataset.shape: ' + str(train_dataset.shape))\n",
    "print('test_dataset.shape： ' + str(test_dataset.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 看一下数据分布\n",
    "通俗一点：看点是不是能聚在一起\n",
    "[seaborn.pairplot文档说明](https://seaborn.pydata.org/generated/seaborn.pairplot.html#seaborn.pairplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 用图来查看数据分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\", \"Acceleration\"]], diag_kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 使用Pandas查看数据分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"MPG\")\n",
    "train_stats = train_stats.transpose()\n",
    "print(train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 分别从训练数据和测试数据中分理出标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 数据标准化\n",
    "NOTE: std决定是不是需要标准化，这里使用Pandas处理，也可以使用numpy处理\n",
    "```python\n",
    "normed_train_data = train_dataset.to_numpy()\n",
    "mean = normed_train_data.mean(axis=0)\n",
    "normed_train_data -= mean\n",
    "std = normed_train_data.std(axis=0)\n",
    "normed_train_data /= std\n",
    "\n",
    "normed_test_data = test_dataset.to_numpy()\n",
    "normed_test_data -=mean\n",
    "normed_test_data /=std\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 再来看一下标准化后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = normed_train_data.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "print(train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential(\n",
    "    [\n",
    "        # NOTE： 飞驰人生：一顿操作猛如虎，定睛一看原地杵。\n",
    "        layers.Dense(64, activation=activations.relu, input_shape=(normed_train_data.shape[1],)),\n",
    "        layers.Dense(64, activation=activations.relu),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=losses.mean_squared_error,\n",
    "    optimizer=optimizers.RMSprop(0.001),\n",
    "    metrics=['mean_absolute_error', 'mean_squared_error']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    normed_train_data,\n",
    "    train_labels,\n",
    "    epochs=1000, \n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 查看训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [MPG]')\n",
    "    plt.plot(hist['epoch'], hist['mean_absolute_error'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_absolute_error'], label = 'Val Error')\n",
    "    plt.ylim([0,5])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mean_squared_error'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mean_squared_error'], label = 'Val Error')\n",
    "    plt.ylim([0,20])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 使用tf.keras.callbacks.EarlyStopping提前终止训练\n",
    "\n",
    "NOTE: 自动化控制将是深度学习的一个重要发展方向\n",
    "\n",
    "callbacks参数允许通过编程的方式干预学习过程，比如：\n",
    "- 当发生过拟合的时候 `提前终止学习`、\n",
    "- 学习过程分步 `保存模型`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(normed_train_data, train_labels, epochs=1000, validation_split = 0.2, verbose=0, callbacks=[early_stop])\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 使用测试集评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 在测试集上使用模型预测结果\n",
    "\n",
    "使用plt图形化显示误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(normed_test_data).flatten()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 看看误差值是否服从高斯正态分布\n",
    "\n",
    "NOTE: 扩展一下 6 Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = test_predictions - test_labels\n",
    "plt.hist(error, bins = 25)\n",
    "plt.xlabel(\"Prediction Error [MPG]\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/gaussian-distribution.jpg\" />\n",
    "<center>\n",
    "    平均值为 μ 标准差为 σ 的正态分布\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
